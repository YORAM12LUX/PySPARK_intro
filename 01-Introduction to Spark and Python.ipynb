{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Spark and Python\n",
    "\n",
    "Let's learn how to use Spark with Python by using the pyspark library! Make sure to view the video lecture explaining Spark and RDDs before continuing on with this code.\n",
    "\n",
    "This notebook will serve as reference code for the Big Data section of the course involving Amazon Web Services. The video will provide fuller explanations for what the code is doing.\n",
    "\n",
    "## Creating a SparkContext\n",
    "\n",
    "First we need to create a SparkContext. We will import this from pyspark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_spark_session(\n",
    "    app_name, driver_cores, driver_mem, max_executors, executor_cores,\n",
    "    executor_mem, queue\n",
    "):\n",
    "    \"\"\"Build Spark session.\"\"\"\n",
    "    return (\n",
    "        SparkSession.builder\n",
    "        .appName(app_name)\n",
    "        .config(\"spark.master\", \"yarn\")\n",
    "        .config(\"spark.submit.deployMode\", \"client\")\n",
    "        .config(\"spark.driver.cores\", driver_cores)\n",
    "        .config(\"spark.driver.memory\", driver_mem)\n",
    "        .config(\"spark.executor.cores\", executor_cores)\n",
    "        .config(\"spark.executor.memory\", executor_mem)\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\n",
    "        .config(\"spark.dynamicAllocation.minExecutors\", 0)\n",
    "        .config(\"spark.dynamicAllocation.maxExecutors\", max_executors)\n",
    "        .config(\"spark.executor.memoryOverhead\", 2048)\n",
    "        .config(\"spark.driver.memoryOverhead\", 1024)\n",
    "        .config(\"spark.yarn.queue\", queue)\n",
    "        # .config(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "        .config(\"spark.driver.extraClassPath\", \"/soft/ora1210/db/jdbc/lib/ojdbc6.jar\")\n",
    "        .config(\"spark.executor.extraClassPath\", \"/soft/ora1210/db/jdbc/lib/ojdbc6.jar\")\n",
    "        .getOrCreate()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session = SparkSession.builder\\\n",
    "        .appName(\"app_name\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_context = spark_session.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the SparkContext,A SparkContext represents the connection to a Spark cluster, and can be used to create an RDD and broadcast variables on that cluster.\n",
    "\n",
    "*Note! You can only have one SparkContext at a time the way we are running things here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Operations\n",
    "\n",
    "We're going to start with a 'hello world' example, which is just reading a text file. First let's create a text file.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's write an example text file to read, we'll use some special jupyter notebook commands for this, but feel free to use any .txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting example.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile example.txt\n",
    "first line\n",
    "second line\n",
    "third line\n",
    "fourth line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take in the textfile using the **textFile** method off of the SparkContext we created. This method will read a text file from HDFS, a local file system (available on all\n",
    "nodes), or any Hadoop-supported file system URI, and return it as an RDD of Strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textFile = spark_context.textFile('example.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark’s primary abstraction is a distributed collection of items called a Resilient Distributed Dataset (RDD). RDDs can be created from Hadoop InputFormats (such as HDFS files) or by transforming other RDDs. \n",
    "\n",
    "### Actions\n",
    "\n",
    "We have just created an RDD using the textFile method and can perform operations on this object, such as counting the rows.\n",
    "\n",
    "RDDs have actions, which return values, and transformations, which return pointers to new RDDs. Let’s start with a few actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first line'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "\n",
    "Now we can use transformations, for example the filter transformation will return a new RDD with a subset of items in the file. Let's create a sample transformation using the filter() method. This method (just like Python's own filter function) will only return elements that satisfy the condition. Let's try looking for lines that contain the word 'second'. In which case, there should only be one line that has that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "secfind = textFile.filter(lambda line: 'second' in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[4] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RDD\n",
    "secfind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['second line']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform action on transformation\n",
    "secfind.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform action on transformation\n",
    "secfind.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "import datetime\n",
    "\n",
    "l = [(datetime.date(2018,1,3), 'Ankit',25, 'F'),\n",
    "     (datetime.date(2018,2,3), 'Jalfaizy',22, 'M'),\n",
    "     (datetime.date(2018,1,5), 'saurabh',20, 'F'),\n",
    "     (datetime.date(2018,1,12), 'Bala',26, 'F'),\n",
    "     (datetime.date(2018,7,9), 'Jules',19, 'M') ,\n",
    "     (datetime.date(2018,3,18), 'Arild',43, 'M'),\n",
    "     (datetime.date(2018,1,5), 'sarah',20, 'F'),\n",
    "     (datetime.date(2018,8,12), 'Boly',33, 'M'),\n",
    "     (datetime.date(2018,4,6), 'Anita',35, 'F'),\n",
    "     (datetime.date(2018,12,6), 'Jules',22, 'M'),\n",
    "     (datetime.date(2018,7,24), 'Soul',20, 'M'),\n",
    "     (datetime.date(2018,6,17), 'Gral',54, 'F'),\n",
    "     (datetime.date(2018,9,7), 'Apoh',18, 'M'),\n",
    "     (datetime.date(2018,10,4), 'Dony',32, 'M'),\n",
    "     (datetime.date(2018,2,5), 'Tanoh',31, 'M'),\n",
    "     (datetime.date(2018,11,12), 'Issouf',27, 'M'),\n",
    "     (datetime.date(2018,10,3), 'Bilé',29, 'F'),\n",
    "     (datetime.date(2018,5,3), 'Gagnon',20, 'M'),\n",
    "     (datetime.date(2018,3,5), 'Papiss',28, 'F'),\n",
    "     (datetime.date(2018,2,12), 'Kravitz',34, 'F'),\n",
    "     (datetime.date(2018,5,9), 'Mouli',35, 'F'),\n",
    "     (datetime.date(2018,8,3), 'Jacques',27, 'M'),\n",
    "     (datetime.date(2018,12,5), 'soum',22, 'M'),\n",
    "     (datetime.date(2018,4,12), 'MBra',36, 'F')]\n",
    "\n",
    "rdd = spark_session.sparkContext.parallelize(l)\n",
    "people = rdd.map(lambda x: Row(date=x[0], name=x[1], age=int(x[2]), sexe=x[3]))\n",
    "schemaPeople = spark_session.createDataFrame(people)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexe</th>\n",
       "      <th>nb_sexe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sexe  nb_sexe\n",
       "0    F       11\n",
       "1    M       13"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schemaPeople.groupby(\"sexe\").agg(f.count(\"*\").alias('nb_sexe')).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>sexe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>Arild</td>\n",
       "      <td>43</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-08-12</td>\n",
       "      <td>Boly</td>\n",
       "      <td>33</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>Anita</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-06-17</td>\n",
       "      <td>Gral</td>\n",
       "      <td>54</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>Dony</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>Tanoh</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>Kravitz</td>\n",
       "      <td>34</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>Mouli</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-04-12</td>\n",
       "      <td>MBra</td>\n",
       "      <td>36</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     name  age sexe\n",
       "0  2018-03-18    Arild   43    M\n",
       "1  2018-08-12     Boly   33    M\n",
       "2  2018-04-06    Anita   35    F\n",
       "3  2018-06-17     Gral   54    F\n",
       "4  2018-10-04     Dony   32    M\n",
       "5  2018-02-05    Tanoh   31    M\n",
       "6  2018-02-12  Kravitz   34    F\n",
       "7  2018-05-09    Mouli   35    F\n",
       "8  2018-04-12     MBra   36    F"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schemaPeople.filter(schemaPeople[\"age\"] > 30).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schemaPeople.filter(schemaPeople[\"age\"] > 30).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>sexe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>Anita</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Bilé</td>\n",
       "      <td>29</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-05</td>\n",
       "      <td>Papiss</td>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>Mouli</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-12</td>\n",
       "      <td>MBra</td>\n",
       "      <td>36</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    name  age sexe\n",
       "0  2018-04-06   Anita   35    F\n",
       "1  2018-10-03    Bilé   29    F\n",
       "2  2018-03-05  Papiss   28    F\n",
       "3  2018-05-09   Mouli   35    F\n",
       "4  2018-04-12    MBra   36    F"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Le nombre de personne qui sont nées après le 01-03-2018 et qui ont un âge inférieur à 40 ans et qui sont fille\n",
    "date_limit = \"2018-03-01\"\n",
    "\n",
    "# Filtrer les personnes selon les critères\n",
    "schemaPeople.filter(\n",
    "    (schemaPeople[\"date\"] > date_limit) &  # Nées après le 01-03-2018\n",
    "    (schemaPeople[\"age\"] < 40) &          # Âge inférieur à 40 ans\n",
    "    (schemaPeople[\"sexe\"] == \"F\")         # Sexe féminin\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---+----+----------+\n",
      "|      date|   name|age|sexe|Generation|\n",
      "+----------+-------+---+----+----------+\n",
      "|2018-01-03|  Ankit| 25|   F|   vieille|\n",
      "|2018-01-05|saurabh| 20|   F|     jeune|\n",
      "|2018-01-12|   Bala| 26|   F|   vieille|\n",
      "|2018-01-05|  sarah| 20|   F|     jeune|\n",
      "|2018-04-06|  Anita| 35|   F|   vieille|\n",
      "|2018-06-17|   Gral| 54|   F|   vieille|\n",
      "|2018-10-03|   Bilé| 29|   F|   vieille|\n",
      "|2018-03-05| Papiss| 28|   F|   vieille|\n",
      "|2018-02-12|Kravitz| 34|   F|   vieille|\n",
      "|2018-05-09|  Mouli| 35|   F|   vieille|\n",
      "|2018-04-12|   MBra| 36|   F|   vieille|\n",
      "+----------+-------+---+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Détecer les filles qui ont moins de 25 ans \n",
    "\n",
    "# Filtrer uniquement les filles\n",
    "filtered_girls_df = schemaPeople.filter(schemaPeople[\"sexe\"] == \"F\")\n",
    "\n",
    "# Ajouter une colonne \"tag\" pour différencier jeunes et vieilles filles\n",
    "tagged_girls_df = filtered_girls_df.withColumn(\n",
    "    \"Generation\",\n",
    "    f.when(filtered_girls_df[\"age\"] < 25, \"jeune\").otherwise(\"vieille\")\n",
    ")\n",
    "\n",
    "# Afficher les résultats\n",
    "tagged_girls_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---+----+-----------+\n",
      "|      date|    name|age|sexe|     Status|\n",
      "+----------+--------+---+----+-----------+\n",
      "|2018-01-03|   Ankit| 25|   F|      Autre|\n",
      "|2018-02-03|Jalfaizy| 22|   M|      Autre|\n",
      "|2018-01-05| saurabh| 20|   F|Jeune Fille|\n",
      "|2018-01-12|    Bala| 26|   F|      Autre|\n",
      "|2018-07-09|   Jules| 19|   M|      Autre|\n",
      "|2018-03-18|   Arild| 43|   M|      Autre|\n",
      "|2018-01-05|   sarah| 20|   F|Jeune Fille|\n",
      "|2018-08-12|    Boly| 33|   M|      Autre|\n",
      "|2018-04-06|   Anita| 35|   F|      Autre|\n",
      "|2018-12-06|   Jules| 22|   M|      Autre|\n",
      "|2018-07-24|    Soul| 20|   M|      Autre|\n",
      "|2018-06-17|    Gral| 54|   F|      Autre|\n",
      "|2018-09-07|    Apoh| 18|   M|      Autre|\n",
      "|2018-10-04|    Dony| 32|   M|      Autre|\n",
      "|2018-02-05|   Tanoh| 31|   M|      Autre|\n",
      "|2018-11-12|  Issouf| 27|   M|      Autre|\n",
      "|2018-10-03|    Bilé| 29|   F|      Autre|\n",
      "|2018-05-03|  Gagnon| 20|   M|      Autre|\n",
      "|2018-03-05|  Papiss| 28|   F|      Autre|\n",
      "|2018-02-12| Kravitz| 34|   F|      Autre|\n",
      "+----------+--------+---+----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a=schemaPeople.withColumn('Status',f.when((f.col('age') < 25) & (f.col('sexe')=='F'),'Jeune Fille').otherwise(\"Autre\"))\n",
    "a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---+----+-----------+\n",
      "|      date|    name|age|sexe|  Categorie|\n",
      "+----------+--------+---+----+-----------+\n",
      "|2018-01-03|   Ankit| 25|   F|      Autre|\n",
      "|2018-02-03|Jalfaizy| 22|   M|      Autre|\n",
      "|2018-01-05| saurabh| 20|   F|Jeune Fille|\n",
      "|2018-01-12|    Bala| 26|   F|      Autre|\n",
      "|2018-07-09|   Jules| 19|   M|      Autre|\n",
      "|2018-03-18|   Arild| 43|   M|      Autre|\n",
      "|2018-01-05|   sarah| 20|   F|Jeune Fille|\n",
      "|2018-08-12|    Boly| 33|   M|      Autre|\n",
      "|2018-04-06|   Anita| 35|   F|      Autre|\n",
      "|2018-12-06|   Jules| 22|   M|      Autre|\n",
      "|2018-07-24|    Soul| 20|   M|      Autre|\n",
      "|2018-06-17|    Gral| 54|   F|      Autre|\n",
      "|2018-09-07|    Apoh| 18|   M|      Autre|\n",
      "|2018-10-04|    Dony| 32|   M|      Autre|\n",
      "|2018-02-05|   Tanoh| 31|   M|      Autre|\n",
      "|2018-11-12|  Issouf| 27|   M|      Autre|\n",
      "|2018-10-03|    Bilé| 29|   F|      Autre|\n",
      "|2018-05-03|  Gagnon| 20|   M|      Autre|\n",
      "|2018-03-05|  Papiss| 28|   F|      Autre|\n",
      "|2018-02-12| Kravitz| 34|   F|      Autre|\n",
      "+----------+--------+---+----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = a.withColumnRenamed('Status','Categorie')\n",
    "a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- sexe: string (nullable = true)\n",
      "\n",
      "+----------+--------+---+----+\n",
      "|      date|    name|age|sexe|\n",
      "+----------+--------+---+----+\n",
      "|2018-01-03|   Ankit| 25|   F|\n",
      "|2018-02-03|Jalfaizy| 22|   M|\n",
      "|2018-01-05| saurabh| 20|   F|\n",
      "|2018-01-12|    Bala| 26|   F|\n",
      "|2018-07-09|   Jules| 19|   M|\n",
      "|2018-03-18|   Arild| 43|   M|\n",
      "|2018-01-05|   sarah| 20|   F|\n",
      "|2018-08-12|    Boly| 33|   M|\n",
      "|2018-04-06|   Anita| 35|   F|\n",
      "|2018-12-06|   Jules| 22|   M|\n",
      "|2018-07-24|    Soul| 20|   M|\n",
      "|2018-06-17|    Gral| 54|   F|\n",
      "|2018-09-07|    Apoh| 18|   M|\n",
      "|2018-10-04|    Dony| 32|   M|\n",
      "|2018-02-05|   Tanoh| 31|   M|\n",
      "|2018-11-12|  Issouf| 27|   M|\n",
      "|2018-10-03|    Bilé| 29|   F|\n",
      "|2018-05-03|  Gagnon| 20|   M|\n",
      "|2018-03-05|  Papiss| 28|   F|\n",
      "|2018-02-12| Kravitz| 34|   F|\n",
      "+----------+--------+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemaPeople.printSchema()\n",
    "schemaPeople.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1- compter le nombre de personne totale 2- compter le nombre de fille et de garcon 3- quel est l'age moyen, median mini et maxi dans chaque groupe (garcon, fille) 4 - quelle est le nombre de jours écoulé depuis la dernière visite pour chaque client (la colonne date correspond à la date de visite) 5 - quels sont les personnes qui ont une date de visite < 400 jours. 6- verifier si il existe des valeurs manquantes dans les données 7- rajouter une colonne mois correspondant au mois de chaque individu dans le data frame 8- creer une colonne adulte qui prendra la valeur 0 pour les personnes de moins de 25ans et 1 dans le cas contraire\n",
    "sauvegarder le dataframe schemapeople sous le format parquet dans le repertoire people.parquet en 2 partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(os.getcwd(), \"tagged_girls.csv\")\n",
    "a.coalesce(1).write.option(\"header\", \"true\").csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "# Date actuelle\n",
    "current_date = datetime.date.today()\n",
    "\n",
    "# Chemin du fichier\n",
    "filepath = \"data_repository\"\n",
    "filename = os.path.join(\n",
    "    filepath,\n",
    "    str(current_date.year),\n",
    "    str(current_date.month).zfill(2),\n",
    "    str(current_date.day).zfill(2)\n",
    ")\n",
    "\n",
    "# Écriture du DataFrame en format parquet\n",
    "schemaPeople.coalesce(2).write.mode(\"overwrite\").parquet(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_repository/2024/12/05'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(PB='PB ALBOU', CONTRAT_RATTACHEMENT='AQUAWASH DT - 42257', COMMUNE='BOIGNY SUR BIONNE', CODE_CYCLE_SERVICE='0DYL            ', LIBELLE_CYCLE_SERVICE='BOIGNY SUR BIONNE SEMESTRIEL (Lot 1)', CODE_TOURNEE='0DYL            ', LIBELLE_TOURNEE_SERVICE='BOIGNY SUR BIONNE SEMESTRIEL (Lot 1)', TOURNEE_OPALE=1.0, SEQ_TOURNEE=9700, ID_COMPTEUR=8361561125, NUMERO_BADGE=1581412316, NUMERO_SERIE='H24VA169824', FABRICANT='Sappel - Diehl Metering - MID', MODELE='ALTAIR V4 composite T50', DIAMETRE=15, ANNEE_FABRICATION=2024, SOLUTION_COMPACTE='Oui', SOLUTION_DEPORTEE='Oui', PASSERELLE_SITE_ISOLE='Oui', DATE_RECEPTION='04/09/2024', DATE_DEPOSE=None, MATRICULE_EQUIPEMENT='11A5241011931007', ACCESSIBLE='OUI', CODE_EMPLACEMENT='AJ  ', LIBELLE_EMPLACEMENT='Jardin - Accessible', DETAILS_EMPLACEMENTS='JARDIN CHIENS', ID_PDS=6447593, DATE_MISE_EN_SERVICE_PDS='01/01/2009', ETAT_PDS='En service', ETAT_SOURCE_PDS='Ouvert', LOGEMENT_VACANT='NON      ', GEN_DIV='Normal       ', RACCORDE_RACORDABLE='Raccordable raccordé', DATE_RACCORDABILITE='05/09/2024', USAGE='Normal', FLUIDE='Eau Froide', MAT_BRANCH_AV_COMPT='Inconnu', MAT_AP_COMPT='Inconnu', CALIBRE_BRANCHEMENT=None, MODE_DE_RELEVE='Télé-Relevé', BRANCHEMENT_FICTIF=None, ID_SITE=5734466, FORAGE=None, NUM_VOIE_SITE='51', COMMUNE_SITE='BOIGNY SUR BIONNE', CODE_INSEE_SITE='45034', CODE_POSTAL_SITE=45760, ANC_A_FACTURER=None, BASSINS_VERSANTS=None, NOMBRE_UL=None, ID_COMPTE_CLIENT=9573027089, ANCIENNE_REF_CLIENT='0769603401027901', MENSUALISE='NON', CLASSE_CLIENT='Particulier', COMMUNE_CLIENT='BOIGNY SUR BIONNE', CODE_INSEE_CLIENT='45034', CODE_POSTAL_CLIENT='45760', CMJ='0,101', DATE_DERNIERE_RELEVE='04/09/2024', TYPE_RELEVE='Normal', INDEX_DERNIERE_RELEVE=0, CODE_REM1=None, CODE_REM2=None, CODE_REM3=None, CODE_REM4=None, DT_FIN_CONTRAT_CADRE='30/09/2031', CGC='Non', MO_RES=None, NAT_REJ=None, IMPS_TRRR=None, TYPE_SITE='01 Maison', CODE_NAF=None, LIBELLE_NAF=None, PDS_STRATEGIQUE=None, CARNET_METROLOGIQUE='AKDQ', ID_ACTEUR=2089525014, NATURE_CONTRAT_RATTACHEMENT='DSP', NATURE_SERV_EAU_ASS='EAU', CODE_PROTECTION=None, ID_DERNIERE_RELEVE='8,366E+11', VOLUME_FORAGE_SITE=None, EFACTURE='Non', CODE_REF_AGENCE_EAU=None, L_REF_AGENCE_EAU=None, L_MOD_CONTACT_PRIVILEGE='Pas de préférence', CODE_HEXAVIA=876561, ID_PDS_GEN=None, SIRET=None, NB_LOG=None, NB_MIG=None, NB_PRO=None, NB_TOU=None, NB_UG1=None, NB_UG2=None, NB_UG3=None, NB_UG4=None, NB_UG5=None, FLG_ENT_NAT='Non', SOURCE_RELEVE='Relève à pied', CODE_INT1=None, CODE_INT2=None, SIRET_EMETTEUR='9,80683E+13', FACTURE='OUI')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Skip Bad Lines\").getOrCreate()\n",
    "\n",
    "# Chemin du fichier CSV\n",
    "file_path = \"/home/jovyan/code/PBAL_Parc compteur_202409.csv\"\n",
    "\n",
    "# Lire le fichier CSV en ignorant les lignes mal formatées\n",
    "df = spark.read.csv(\n",
    "    file_path,\n",
    "    header=True,      # Considère la première ligne comme un en-tête\n",
    "    inferSchema=True, # Infère automatiquement les types des colonnes\n",
    "    sep=\";\",\n",
    "    mode=\"PERMISSIVE\" # Tolère les erreurs de format\n",
    ")\n",
    "\n",
    "# Afficher les premières lignes\n",
    "#df.show(truncate=False)  # Affiche toutes les colonnes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PB: string (nullable = true)\n",
      " |-- CONTRAT_RATTACHEMENT: string (nullable = true)\n",
      " |-- COMMUNE: string (nullable = true)\n",
      " |-- CODE_CYCLE_SERVICE: string (nullable = true)\n",
      " |-- LIBELLE_CYCLE_SERVICE: string (nullable = true)\n",
      " |-- CODE_TOURNEE: string (nullable = true)\n",
      " |-- LIBELLE_TOURNEE_SERVICE: string (nullable = true)\n",
      " |-- TOURNEE_OPALE: double (nullable = true)\n",
      " |-- SEQ_TOURNEE: integer (nullable = true)\n",
      " |-- ID_COMPTEUR: long (nullable = true)\n",
      " |-- NUMERO_BADGE: integer (nullable = true)\n",
      " |-- NUMERO_SERIE: string (nullable = true)\n",
      " |-- FABRICANT: string (nullable = true)\n",
      " |-- MODELE: string (nullable = true)\n",
      " |-- DIAMETRE: integer (nullable = true)\n",
      " |-- ANNEE_FABRICATION: integer (nullable = true)\n",
      " |-- SOLUTION_COMPACTE: string (nullable = true)\n",
      " |-- SOLUTION_DEPORTEE: string (nullable = true)\n",
      " |-- PASSERELLE_SITE_ISOLE: string (nullable = true)\n",
      " |-- DATE_RECEPTION: string (nullable = true)\n",
      " |-- DATE_DEPOSE: string (nullable = true)\n",
      " |-- MATRICULE_EQUIPEMENT: string (nullable = true)\n",
      " |-- ACCESSIBLE: string (nullable = true)\n",
      " |-- CODE_EMPLACEMENT: string (nullable = true)\n",
      " |-- LIBELLE_EMPLACEMENT: string (nullable = true)\n",
      " |-- DETAILS_EMPLACEMENTS: string (nullable = true)\n",
      " |-- ID_PDS: long (nullable = true)\n",
      " |-- DATE_MISE_EN_SERVICE_PDS: string (nullable = true)\n",
      " |-- ETAT_PDS: string (nullable = true)\n",
      " |-- ETAT_SOURCE_PDS: string (nullable = true)\n",
      " |-- LOGEMENT_VACANT: string (nullable = true)\n",
      " |-- GEN_DIV: string (nullable = true)\n",
      " |-- RACCORDE_RACORDABLE: string (nullable = true)\n",
      " |-- DATE_RACCORDABILITE: string (nullable = true)\n",
      " |-- USAGE: string (nullable = true)\n",
      " |-- FLUIDE: string (nullable = true)\n",
      " |-- MAT_BRANCH_AV_COMPT: string (nullable = true)\n",
      " |-- MAT_AP_COMPT: string (nullable = true)\n",
      " |-- CALIBRE_BRANCHEMENT: integer (nullable = true)\n",
      " |-- MODE_DE_RELEVE: string (nullable = true)\n",
      " |-- BRANCHEMENT_FICTIF: string (nullable = true)\n",
      " |-- ID_SITE: long (nullable = true)\n",
      " |-- FORAGE: string (nullable = true)\n",
      " |-- NUM_VOIE_SITE: string (nullable = true)\n",
      " |-- COMMUNE_SITE: string (nullable = true)\n",
      " |-- CODE_INSEE_SITE: string (nullable = true)\n",
      " |-- CODE_POSTAL_SITE: integer (nullable = true)\n",
      " |-- ANC_A_FACTURER: string (nullable = true)\n",
      " |-- BASSINS_VERSANTS: string (nullable = true)\n",
      " |-- NOMBRE_UL: string (nullable = true)\n",
      " |-- ID_COMPTE_CLIENT: long (nullable = true)\n",
      " |-- ANCIENNE_REF_CLIENT: string (nullable = true)\n",
      " |-- MENSUALISE: string (nullable = true)\n",
      " |-- CLASSE_CLIENT: string (nullable = true)\n",
      " |-- COMMUNE_CLIENT: string (nullable = true)\n",
      " |-- CODE_INSEE_CLIENT: string (nullable = true)\n",
      " |-- CODE_POSTAL_CLIENT: string (nullable = true)\n",
      " |-- CMJ: string (nullable = true)\n",
      " |-- DATE_DERNIERE_RELEVE: string (nullable = true)\n",
      " |-- TYPE_RELEVE: string (nullable = true)\n",
      " |-- INDEX_DERNIERE_RELEVE: integer (nullable = true)\n",
      " |-- CODE_REM1: string (nullable = true)\n",
      " |-- CODE_REM2: string (nullable = true)\n",
      " |-- CODE_REM3: string (nullable = true)\n",
      " |-- CODE_REM4: string (nullable = true)\n",
      " |-- DT_FIN_CONTRAT_CADRE: string (nullable = true)\n",
      " |-- CGC: string (nullable = true)\n",
      " |-- MO_RES: string (nullable = true)\n",
      " |-- NAT_REJ: string (nullable = true)\n",
      " |-- IMPS_TRRR: string (nullable = true)\n",
      " |-- TYPE_SITE: string (nullable = true)\n",
      " |-- CODE_NAF: string (nullable = true)\n",
      " |-- LIBELLE_NAF: string (nullable = true)\n",
      " |-- PDS_STRATEGIQUE: string (nullable = true)\n",
      " |-- CARNET_METROLOGIQUE: string (nullable = true)\n",
      " |-- ID_ACTEUR: long (nullable = true)\n",
      " |-- NATURE_CONTRAT_RATTACHEMENT: string (nullable = true)\n",
      " |-- NATURE_SERV_EAU_ASS: string (nullable = true)\n",
      " |-- CODE_PROTECTION: string (nullable = true)\n",
      " |-- ID_DERNIERE_RELEVE: string (nullable = true)\n",
      " |-- VOLUME_FORAGE_SITE: string (nullable = true)\n",
      " |-- EFACTURE: string (nullable = true)\n",
      " |-- CODE_REF_AGENCE_EAU: string (nullable = true)\n",
      " |-- L_REF_AGENCE_EAU: string (nullable = true)\n",
      " |-- L_MOD_CONTACT_PRIVILEGE: string (nullable = true)\n",
      " |-- CODE_HEXAVIA: integer (nullable = true)\n",
      " |-- ID_PDS_GEN: long (nullable = true)\n",
      " |-- SIRET: string (nullable = true)\n",
      " |-- NB_LOG: string (nullable = true)\n",
      " |-- NB_MIG: string (nullable = true)\n",
      " |-- NB_PRO: string (nullable = true)\n",
      " |-- NB_TOU: string (nullable = true)\n",
      " |-- NB_UG1: string (nullable = true)\n",
      " |-- NB_UG2: string (nullable = true)\n",
      " |-- NB_UG3: string (nullable = true)\n",
      " |-- NB_UG4: string (nullable = true)\n",
      " |-- NB_UG5: string (nullable = true)\n",
      " |-- FLG_ENT_NAT: string (nullable = true)\n",
      " |-- SOURCE_RELEVE: string (nullable = true)\n",
      " |-- CODE_INT1: string (nullable = true)\n",
      " |-- CODE_INT2: string (nullable = true)\n",
      " |-- SIRET_EMETTEUR: string (nullable = true)\n",
      " |-- FACTURE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PB: string (nullable = true)\n",
      " |-- CONTRAT_RATTACHEMENT: string (nullable = true)\n",
      " |-- COMMUNE: string (nullable = true)\n",
      " |-- CODE_CYCLE_SERVICE: string (nullable = true)\n",
      " |-- LIBELLE_CYCLE_SERVICE: string (nullable = true)\n",
      " |-- CODE_TOURNEE: string (nullable = true)\n",
      " |-- LIBELLE_TOURNEE_SERVICE: string (nullable = true)\n",
      " |-- TOURNEE_OPALE: double (nullable = true)\n",
      " |-- SEQ_TOURNEE: integer (nullable = true)\n",
      " |-- ID_COMPTEUR: long (nullable = true)\n",
      " |-- NUMERO_BADGE: integer (nullable = true)\n",
      " |-- NUMERO_SERIE: string (nullable = true)\n",
      " |-- FABRICANT: string (nullable = true)\n",
      " |-- MODELE: string (nullable = true)\n",
      " |-- DIAMETRE: integer (nullable = true)\n",
      " |-- ANNEE_FABRICATION: integer (nullable = true)\n",
      " |-- SOLUTION_COMPACTE: string (nullable = true)\n",
      " |-- SOLUTION_DEPORTEE: string (nullable = true)\n",
      " |-- PASSERELLE_SITE_ISOLE: string (nullable = true)\n",
      " |-- DATE_RECEPTION: date (nullable = true)\n",
      " |-- DATE_DEPOSE: date (nullable = true)\n",
      " |-- MATRICULE_EQUIPEMENT: string (nullable = true)\n",
      " |-- ACCESSIBLE: string (nullable = true)\n",
      " |-- CODE_EMPLACEMENT: string (nullable = true)\n",
      " |-- LIBELLE_EMPLACEMENT: string (nullable = true)\n",
      " |-- DETAILS_EMPLACEMENTS: string (nullable = true)\n",
      " |-- ID_PDS: long (nullable = true)\n",
      " |-- DATE_MISE_EN_SERVICE_PDS: date (nullable = true)\n",
      " |-- ETAT_PDS: string (nullable = true)\n",
      " |-- ETAT_SOURCE_PDS: string (nullable = true)\n",
      " |-- LOGEMENT_VACANT: string (nullable = true)\n",
      " |-- GEN_DIV: string (nullable = true)\n",
      " |-- RACCORDE_RACORDABLE: string (nullable = true)\n",
      " |-- DATE_RACCORDABILITE: date (nullable = true)\n",
      " |-- USAGE: string (nullable = true)\n",
      " |-- FLUIDE: string (nullable = true)\n",
      " |-- MAT_BRANCH_AV_COMPT: string (nullable = true)\n",
      " |-- MAT_AP_COMPT: string (nullable = true)\n",
      " |-- CALIBRE_BRANCHEMENT: integer (nullable = true)\n",
      " |-- MODE_DE_RELEVE: string (nullable = true)\n",
      " |-- BRANCHEMENT_FICTIF: string (nullable = true)\n",
      " |-- ID_SITE: long (nullable = true)\n",
      " |-- FORAGE: string (nullable = true)\n",
      " |-- NUM_VOIE_SITE: string (nullable = true)\n",
      " |-- COMMUNE_SITE: string (nullable = true)\n",
      " |-- CODE_INSEE_SITE: string (nullable = true)\n",
      " |-- CODE_POSTAL_SITE: integer (nullable = true)\n",
      " |-- ANC_A_FACTURER: string (nullable = true)\n",
      " |-- BASSINS_VERSANTS: string (nullable = true)\n",
      " |-- NOMBRE_UL: string (nullable = true)\n",
      " |-- ID_COMPTE_CLIENT: long (nullable = true)\n",
      " |-- ANCIENNE_REF_CLIENT: string (nullable = true)\n",
      " |-- MENSUALISE: string (nullable = true)\n",
      " |-- CLASSE_CLIENT: string (nullable = true)\n",
      " |-- COMMUNE_CLIENT: string (nullable = true)\n",
      " |-- CODE_INSEE_CLIENT: string (nullable = true)\n",
      " |-- CODE_POSTAL_CLIENT: string (nullable = true)\n",
      " |-- CMJ: string (nullable = true)\n",
      " |-- DATE_DERNIERE_RELEVE: date (nullable = true)\n",
      " |-- TYPE_RELEVE: string (nullable = true)\n",
      " |-- INDEX_DERNIERE_RELEVE: integer (nullable = true)\n",
      " |-- CODE_REM1: string (nullable = true)\n",
      " |-- CODE_REM2: string (nullable = true)\n",
      " |-- CODE_REM3: string (nullable = true)\n",
      " |-- CODE_REM4: string (nullable = true)\n",
      " |-- DT_FIN_CONTRAT_CADRE: date (nullable = true)\n",
      " |-- CGC: string (nullable = true)\n",
      " |-- MO_RES: string (nullable = true)\n",
      " |-- NAT_REJ: string (nullable = true)\n",
      " |-- IMPS_TRRR: string (nullable = true)\n",
      " |-- TYPE_SITE: string (nullable = true)\n",
      " |-- CODE_NAF: string (nullable = true)\n",
      " |-- LIBELLE_NAF: string (nullable = true)\n",
      " |-- PDS_STRATEGIQUE: string (nullable = true)\n",
      " |-- CARNET_METROLOGIQUE: string (nullable = true)\n",
      " |-- ID_ACTEUR: long (nullable = true)\n",
      " |-- NATURE_CONTRAT_RATTACHEMENT: string (nullable = true)\n",
      " |-- NATURE_SERV_EAU_ASS: string (nullable = true)\n",
      " |-- CODE_PROTECTION: string (nullable = true)\n",
      " |-- ID_DERNIERE_RELEVE: string (nullable = true)\n",
      " |-- VOLUME_FORAGE_SITE: string (nullable = true)\n",
      " |-- EFACTURE: string (nullable = true)\n",
      " |-- CODE_REF_AGENCE_EAU: string (nullable = true)\n",
      " |-- L_REF_AGENCE_EAU: string (nullable = true)\n",
      " |-- L_MOD_CONTACT_PRIVILEGE: string (nullable = true)\n",
      " |-- CODE_HEXAVIA: integer (nullable = true)\n",
      " |-- ID_PDS_GEN: long (nullable = true)\n",
      " |-- SIRET: string (nullable = true)\n",
      " |-- NB_LOG: string (nullable = true)\n",
      " |-- NB_MIG: string (nullable = true)\n",
      " |-- NB_PRO: string (nullable = true)\n",
      " |-- NB_TOU: string (nullable = true)\n",
      " |-- NB_UG1: string (nullable = true)\n",
      " |-- NB_UG2: string (nullable = true)\n",
      " |-- NB_UG3: string (nullable = true)\n",
      " |-- NB_UG4: string (nullable = true)\n",
      " |-- NB_UG5: string (nullable = true)\n",
      " |-- FLG_ENT_NAT: string (nullable = true)\n",
      " |-- SOURCE_RELEVE: string (nullable = true)\n",
      " |-- CODE_INT1: string (nullable = true)\n",
      " |-- CODE_INT2: string (nullable = true)\n",
      " |-- SIRET_EMETTEUR: string (nullable = true)\n",
      " |-- FACTURE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(PB='PB ALBOU', CONTRAT_RATTACHEMENT='AQUAWASH DT - 42257', COMMUNE='BOIGNY SUR BIONNE', CODE_CYCLE_SERVICE='0DYL            ', LIBELLE_CYCLE_SERVICE='BOIGNY SUR BIONNE SEMESTRIEL (Lot 1)', CODE_TOURNEE='0DYL            ', LIBELLE_TOURNEE_SERVICE='BOIGNY SUR BIONNE SEMESTRIEL (Lot 1)', TOURNEE_OPALE=1.0, SEQ_TOURNEE=9700, ID_COMPTEUR=8361561125, NUMERO_BADGE=1581412316, NUMERO_SERIE='H24VA169824', FABRICANT='Sappel - Diehl Metering - MID', MODELE='ALTAIR V4 composite T50', DIAMETRE=15, ANNEE_FABRICATION=2024, SOLUTION_COMPACTE='Oui', SOLUTION_DEPORTEE='Oui', PASSERELLE_SITE_ISOLE='Oui', DATE_RECEPTION=datetime.date(2024, 9, 4), DATE_DEPOSE=None, MATRICULE_EQUIPEMENT='11A5241011931007', ACCESSIBLE='OUI', CODE_EMPLACEMENT='AJ  ', LIBELLE_EMPLACEMENT='Jardin - Accessible', DETAILS_EMPLACEMENTS='JARDIN CHIENS', ID_PDS=6447593, DATE_MISE_EN_SERVICE_PDS=datetime.date(2009, 1, 1), ETAT_PDS='En service', ETAT_SOURCE_PDS='Ouvert', LOGEMENT_VACANT='NON      ', GEN_DIV='Normal       ', RACCORDE_RACORDABLE='Raccordable raccordé', DATE_RACCORDABILITE=datetime.date(2024, 9, 5), USAGE='Normal', FLUIDE='Eau Froide', MAT_BRANCH_AV_COMPT='Inconnu', MAT_AP_COMPT='Inconnu', CALIBRE_BRANCHEMENT=None, MODE_DE_RELEVE='Télé-Relevé', BRANCHEMENT_FICTIF=None, ID_SITE=5734466, FORAGE=None, NUM_VOIE_SITE='51', COMMUNE_SITE='BOIGNY SUR BIONNE', CODE_INSEE_SITE='45034', CODE_POSTAL_SITE=45760, ANC_A_FACTURER=None, BASSINS_VERSANTS=None, NOMBRE_UL=None, ID_COMPTE_CLIENT=9573027089, ANCIENNE_REF_CLIENT='0769603401027901', MENSUALISE='NON', CLASSE_CLIENT='Particulier', COMMUNE_CLIENT='BOIGNY SUR BIONNE', CODE_INSEE_CLIENT='45034', CODE_POSTAL_CLIENT='45760', CMJ='0,101', DATE_DERNIERE_RELEVE=datetime.date(2024, 9, 4), TYPE_RELEVE='Normal', INDEX_DERNIERE_RELEVE=0, CODE_REM1=None, CODE_REM2=None, CODE_REM3=None, CODE_REM4=None, DT_FIN_CONTRAT_CADRE=datetime.date(2031, 9, 30), CGC='Non', MO_RES=None, NAT_REJ=None, IMPS_TRRR=None, TYPE_SITE='01 Maison', CODE_NAF=None, LIBELLE_NAF=None, PDS_STRATEGIQUE=None, CARNET_METROLOGIQUE='AKDQ', ID_ACTEUR=2089525014, NATURE_CONTRAT_RATTACHEMENT='DSP', NATURE_SERV_EAU_ASS='EAU', CODE_PROTECTION=None, ID_DERNIERE_RELEVE='8,366E+11', VOLUME_FORAGE_SITE=None, EFACTURE='Non', CODE_REF_AGENCE_EAU=None, L_REF_AGENCE_EAU=None, L_MOD_CONTACT_PRIVILEGE='Pas de préférence', CODE_HEXAVIA=876561, ID_PDS_GEN=None, SIRET=None, NB_LOG=None, NB_MIG=None, NB_PRO=None, NB_TOU=None, NB_UG1=None, NB_UG2=None, NB_UG3=None, NB_UG4=None, NB_UG5=None, FLG_ENT_NAT='Non', SOURCE_RELEVE='Relève à pied', CODE_INT1=None, CODE_INT2=None, SIRET_EMETTEUR='9,80683E+13', FACTURE='OUI')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(COMMUNE='MARDIE'),\n",
       " Row(COMMUNE='BOU'),\n",
       " Row(COMMUNE='CHECY'),\n",
       " Row(COMMUNE='CHANTEAU'),\n",
       " Row(COMMUNE='BOIGNY SUR BIONNE'),\n",
       " Row(COMMUNE='COMBLEUX'),\n",
       " Row(COMMUNE='MARIGNY LES USAGES'),\n",
       " Row(COMMUNE='OLIVET'),\n",
       " Row(COMMUNE='ORLEANS'),\n",
       " Row(COMMUNE='ORMES'),\n",
       " Row(COMMUNE='ST JEAN DE LA RUELLE'),\n",
       " Row(COMMUNE='SAINT JEAN LE BLANC'),\n",
       " Row(COMMUNE='ST JEAN LE BLANC'),\n",
       " Row(COMMUNE='ST PRYVE ST MESMIN'),\n",
       " Row(COMMUNE='ST JEAN DE BRAYE'),\n",
       " Row(COMMUNE='SARAN'),\n",
       " Row(COMMUNE='ST CYR EN VAL')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher les communes uniques \n",
    "df.select('COMMUNE').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PB: string (nullable = true)\n",
      " |-- CONTRAT_RATTACHEMENT: string (nullable = true)\n",
      " |-- COMMUNE: string (nullable = true)\n",
      " |-- CODE_CYCLE_SERVICE: string (nullable = true)\n",
      " |-- LIBELLE_CYCLE_SERVICE: string (nullable = true)\n",
      " |-- CODE_TOURNEE: string (nullable = true)\n",
      " |-- LIBELLE_TOURNEE_SERVICE: string (nullable = true)\n",
      " |-- TOURNEE_OPALE: string (nullable = true)\n",
      " |-- SEQ_TOURNEE: string (nullable = true)\n",
      " |-- ID_COMPTEUR: string (nullable = true)\n",
      " |-- NUMERO_BADGE: string (nullable = true)\n",
      " |-- NUMERO_SERIE: string (nullable = true)\n",
      " |-- FABRICANT: string (nullable = true)\n",
      " |-- MODELE: string (nullable = true)\n",
      " |-- DIAMETRE: string (nullable = true)\n",
      " |-- ANNEE_FABRICATION: string (nullable = true)\n",
      " |-- SOLUTION_COMPACTE: string (nullable = true)\n",
      " |-- SOLUTION_DEPORTEE: string (nullable = true)\n",
      " |-- PASSERELLE_SITE_ISOLE: string (nullable = true)\n",
      " |-- DATE_RECEPTION: date (nullable = true)\n",
      " |-- DATE_DEPOSE: date (nullable = true)\n",
      " |-- MATRICULE_EQUIPEMENT: string (nullable = true)\n",
      " |-- ACCESSIBLE: string (nullable = true)\n",
      " |-- CODE_EMPLACEMENT: string (nullable = true)\n",
      " |-- LIBELLE_EMPLACEMENT: string (nullable = true)\n",
      " |-- DETAILS_EMPLACEMENTS: string (nullable = true)\n",
      " |-- ID_PDS: string (nullable = true)\n",
      " |-- DATE_MISE_EN_SERVICE_PDS: date (nullable = true)\n",
      " |-- ETAT_PDS: string (nullable = true)\n",
      " |-- ETAT_SOURCE_PDS: string (nullable = true)\n",
      " |-- LOGEMENT_VACANT: string (nullable = true)\n",
      " |-- GEN_DIV: string (nullable = true)\n",
      " |-- RACCORDE_RACORDABLE: string (nullable = true)\n",
      " |-- DATE_RACCORDABILITE: date (nullable = true)\n",
      " |-- USAGE: string (nullable = true)\n",
      " |-- FLUIDE: string (nullable = true)\n",
      " |-- MAT_BRANCH_AV_COMPT: string (nullable = true)\n",
      " |-- MAT_AP_COMPT: string (nullable = true)\n",
      " |-- CALIBRE_BRANCHEMENT: string (nullable = true)\n",
      " |-- MODE_DE_RELEVE: string (nullable = true)\n",
      " |-- BRANCHEMENT_FICTIF: string (nullable = true)\n",
      " |-- ID_SITE: string (nullable = true)\n",
      " |-- FORAGE: string (nullable = true)\n",
      " |-- NUM_VOIE_SITE: string (nullable = true)\n",
      " |-- COMMUNE_SITE: string (nullable = true)\n",
      " |-- CODE_INSEE_SITE: string (nullable = true)\n",
      " |-- CODE_POSTAL_SITE: string (nullable = true)\n",
      " |-- ANC_A_FACTURER: string (nullable = true)\n",
      " |-- BASSINS_VERSANTS: string (nullable = true)\n",
      " |-- NOMBRE_UL: string (nullable = true)\n",
      " |-- ID_COMPTE_CLIENT: string (nullable = true)\n",
      " |-- ANCIENNE_REF_CLIENT: string (nullable = true)\n",
      " |-- MENSUALISE: string (nullable = true)\n",
      " |-- CLASSE_CLIENT: string (nullable = true)\n",
      " |-- COMMUNE_CLIENT: string (nullable = true)\n",
      " |-- CODE_INSEE_CLIENT: string (nullable = true)\n",
      " |-- CODE_POSTAL_CLIENT: string (nullable = true)\n",
      " |-- CMJ: string (nullable = true)\n",
      " |-- DATE_DERNIERE_RELEVE: date (nullable = true)\n",
      " |-- TYPE_RELEVE: string (nullable = true)\n",
      " |-- INDEX_DERNIERE_RELEVE: string (nullable = true)\n",
      " |-- CODE_REM1: string (nullable = true)\n",
      " |-- CODE_REM2: string (nullable = true)\n",
      " |-- CODE_REM3: string (nullable = true)\n",
      " |-- CODE_REM4: string (nullable = true)\n",
      " |-- DT_FIN_CONTRAT_CADRE: date (nullable = true)\n",
      " |-- CGC: string (nullable = true)\n",
      " |-- MO_RES: string (nullable = true)\n",
      " |-- NAT_REJ: string (nullable = true)\n",
      " |-- IMPS_TRRR: string (nullable = true)\n",
      " |-- TYPE_SITE: string (nullable = true)\n",
      " |-- CODE_NAF: string (nullable = true)\n",
      " |-- LIBELLE_NAF: string (nullable = true)\n",
      " |-- PDS_STRATEGIQUE: string (nullable = true)\n",
      " |-- CARNET_METROLOGIQUE: string (nullable = true)\n",
      " |-- ID_ACTEUR: string (nullable = true)\n",
      " |-- NATURE_CONTRAT_RATTACHEMENT: string (nullable = true)\n",
      " |-- NATURE_SERV_EAU_ASS: string (nullable = true)\n",
      " |-- CODE_PROTECTION: string (nullable = true)\n",
      " |-- ID_DERNIERE_RELEVE: string (nullable = true)\n",
      " |-- VOLUME_FORAGE_SITE: string (nullable = true)\n",
      " |-- EFACTURE: string (nullable = true)\n",
      " |-- CODE_REF_AGENCE_EAU: string (nullable = true)\n",
      " |-- L_REF_AGENCE_EAU: string (nullable = true)\n",
      " |-- L_MOD_CONTACT_PRIVILEGE: string (nullable = true)\n",
      " |-- CODE_HEXAVIA: string (nullable = true)\n",
      " |-- ID_PDS_GEN: string (nullable = true)\n",
      " |-- SIRET: string (nullable = true)\n",
      " |-- NB_LOG: string (nullable = true)\n",
      " |-- NB_MIG: string (nullable = true)\n",
      " |-- NB_PRO: string (nullable = true)\n",
      " |-- NB_TOU: string (nullable = true)\n",
      " |-- NB_UG1: string (nullable = true)\n",
      " |-- NB_UG2: string (nullable = true)\n",
      " |-- NB_UG3: string (nullable = true)\n",
      " |-- NB_UG4: string (nullable = true)\n",
      " |-- NB_UG5: string (nullable = true)\n",
      " |-- FLG_ENT_NAT: string (nullable = true)\n",
      " |-- SOURCE_RELEVE: string (nullable = true)\n",
      " |-- CODE_INT1: string (nullable = true)\n",
      " |-- CODE_INT2: string (nullable = true)\n",
      " |-- SIRET_EMETTEUR: string (nullable = true)\n",
      " |-- FACTURE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date, col\n",
    "\n",
    "# Liste des colonnes qui contiennent des dates sous forme de string\n",
    "date_columns = [\n",
    "    \"DATE_RECEPTION\", \"DATE_DEPOSE\", \"DATE_MISE_EN_SERVICE_PDS\", \n",
    "    \"DATE_RACCORDABILITE\", \"DATE_DERNIERE_RELEVE\", \"DT_FIN_CONTRAT_CADRE\"\n",
    "]\n",
    "\n",
    "# Appliquer la conversion pour chaque colonne de type string en date\n",
    "for column in date_columns:\n",
    "    df = df.withColumn(column, to_date(col(column), \"dd/MM/yyyy\"))  # Ajustez le format si nécessaire\n",
    "\n",
    "# Vérifier les changements\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "\n",
    "date_columns = [\n",
    "    \"DATE_RECEPTION\", \"DATE_DEPOSE\", \"DATE_MISE_EN_SERVICE_PDS\", \n",
    "    \"DATE_RACCORDABILITE\", \"DATE_DERNIERE_RELEVE\", \"DT_FIN_CONTRAT_CADRE\"\n",
    "]\n",
    "\n",
    "# 1ere fonction qui clean les donnees en les listants \n",
    "\n",
    "def clean_dataset(df,date_columns ):\n",
    "    df= df.select([f.trim(f.col(c)).alias(c) for c in df.columns])\n",
    "    df=df.select([f.to_date(f.col(column),\"dd/MM/yyyy\").alias(column) if column in date_columns else f.col(column) for column in df.columns ])\n",
    "    df=df.withColumn('COMMUNE',f.when(df[\"COMMUNE\"].isin([\"SARAN\", \"ORLEANS\"]), 'None').otherwise(df[\"COMMUNE\"]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# 2e fonction sans lister les colonnes DATES\n",
    "def clean_dataset2(df):\n",
    "    df= df.select([f.trim(f.col(c)).alias(c) for c in df.columns])\n",
    "    df = df.select(*[f.to_date(f.col(column), \"dd/MM/yyyy\").alias(column) if column.startswith('DATE') or column.startswith('DT') else f.col(column) for column in df.columns])\n",
    "\n",
    "    df=df.withColumn('COMMUNE',f.when(df[\"COMMUNE\"].isin([\"SARAN\", \"ORLEANS\"]), 'None').otherwise(df[\"COMMUNE\"]))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(MODE_DE_RELEVE='A pied'),\n",
       " Row(MODE_DE_RELEVE='Télé-Relevé'),\n",
       " Row(MODE_DE_RELEVE='Radio-Relevé'),\n",
       " Row(MODE_DE_RELEVE=None)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('MODE_DE_RELEVE').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PB: string (nullable = true)\n",
      " |-- CONTRAT_RATTACHEMENT: string (nullable = true)\n",
      " |-- COMMUNE: string (nullable = true)\n",
      " |-- CODE_CYCLE_SERVICE: string (nullable = true)\n",
      " |-- LIBELLE_CYCLE_SERVICE: string (nullable = true)\n",
      " |-- CODE_TOURNEE: string (nullable = true)\n",
      " |-- LIBELLE_TOURNEE_SERVICE: string (nullable = true)\n",
      " |-- TOURNEE_OPALE: string (nullable = true)\n",
      " |-- SEQ_TOURNEE: string (nullable = true)\n",
      " |-- ID_COMPTEUR: string (nullable = true)\n",
      " |-- NUMERO_BADGE: string (nullable = true)\n",
      " |-- NUMERO_SERIE: string (nullable = true)\n",
      " |-- FABRICANT: string (nullable = true)\n",
      " |-- MODELE: string (nullable = true)\n",
      " |-- DIAMETRE: string (nullable = true)\n",
      " |-- ANNEE_FABRICATION: string (nullable = true)\n",
      " |-- SOLUTION_COMPACTE: string (nullable = true)\n",
      " |-- SOLUTION_DEPORTEE: string (nullable = true)\n",
      " |-- PASSERELLE_SITE_ISOLE: string (nullable = true)\n",
      " |-- DATE_RECEPTION: date (nullable = true)\n",
      " |-- DATE_DEPOSE: date (nullable = true)\n",
      " |-- MATRICULE_EQUIPEMENT: string (nullable = true)\n",
      " |-- ACCESSIBLE: string (nullable = true)\n",
      " |-- CODE_EMPLACEMENT: string (nullable = true)\n",
      " |-- LIBELLE_EMPLACEMENT: string (nullable = true)\n",
      " |-- DETAILS_EMPLACEMENTS: string (nullable = true)\n",
      " |-- ID_PDS: string (nullable = true)\n",
      " |-- DATE_MISE_EN_SERVICE_PDS: date (nullable = true)\n",
      " |-- ETAT_PDS: string (nullable = true)\n",
      " |-- ETAT_SOURCE_PDS: string (nullable = true)\n",
      " |-- LOGEMENT_VACANT: string (nullable = true)\n",
      " |-- GEN_DIV: string (nullable = true)\n",
      " |-- RACCORDE_RACORDABLE: string (nullable = true)\n",
      " |-- DATE_RACCORDABILITE: date (nullable = true)\n",
      " |-- USAGE: string (nullable = true)\n",
      " |-- FLUIDE: string (nullable = true)\n",
      " |-- MAT_BRANCH_AV_COMPT: string (nullable = true)\n",
      " |-- MAT_AP_COMPT: string (nullable = true)\n",
      " |-- CALIBRE_BRANCHEMENT: string (nullable = true)\n",
      " |-- MODE_DE_RELEVE: string (nullable = true)\n",
      " |-- BRANCHEMENT_FICTIF: string (nullable = true)\n",
      " |-- ID_SITE: string (nullable = true)\n",
      " |-- FORAGE: string (nullable = true)\n",
      " |-- NUM_VOIE_SITE: string (nullable = true)\n",
      " |-- COMMUNE_SITE: string (nullable = true)\n",
      " |-- CODE_INSEE_SITE: string (nullable = true)\n",
      " |-- CODE_POSTAL_SITE: string (nullable = true)\n",
      " |-- ANC_A_FACTURER: string (nullable = true)\n",
      " |-- BASSINS_VERSANTS: string (nullable = true)\n",
      " |-- NOMBRE_UL: string (nullable = true)\n",
      " |-- ID_COMPTE_CLIENT: string (nullable = true)\n",
      " |-- ANCIENNE_REF_CLIENT: string (nullable = true)\n",
      " |-- MENSUALISE: string (nullable = true)\n",
      " |-- CLASSE_CLIENT: string (nullable = true)\n",
      " |-- COMMUNE_CLIENT: string (nullable = true)\n",
      " |-- CODE_INSEE_CLIENT: string (nullable = true)\n",
      " |-- CODE_POSTAL_CLIENT: string (nullable = true)\n",
      " |-- CMJ: string (nullable = true)\n",
      " |-- DATE_DERNIERE_RELEVE: date (nullable = true)\n",
      " |-- TYPE_RELEVE: string (nullable = true)\n",
      " |-- INDEX_DERNIERE_RELEVE: string (nullable = true)\n",
      " |-- CODE_REM1: string (nullable = true)\n",
      " |-- CODE_REM2: string (nullable = true)\n",
      " |-- CODE_REM3: string (nullable = true)\n",
      " |-- CODE_REM4: string (nullable = true)\n",
      " |-- DT_FIN_CONTRAT_CADRE: date (nullable = true)\n",
      " |-- CGC: string (nullable = true)\n",
      " |-- MO_RES: string (nullable = true)\n",
      " |-- NAT_REJ: string (nullable = true)\n",
      " |-- IMPS_TRRR: string (nullable = true)\n",
      " |-- TYPE_SITE: string (nullable = true)\n",
      " |-- CODE_NAF: string (nullable = true)\n",
      " |-- LIBELLE_NAF: string (nullable = true)\n",
      " |-- PDS_STRATEGIQUE: string (nullable = true)\n",
      " |-- CARNET_METROLOGIQUE: string (nullable = true)\n",
      " |-- ID_ACTEUR: string (nullable = true)\n",
      " |-- NATURE_CONTRAT_RATTACHEMENT: string (nullable = true)\n",
      " |-- NATURE_SERV_EAU_ASS: string (nullable = true)\n",
      " |-- CODE_PROTECTION: string (nullable = true)\n",
      " |-- ID_DERNIERE_RELEVE: string (nullable = true)\n",
      " |-- VOLUME_FORAGE_SITE: string (nullable = true)\n",
      " |-- EFACTURE: string (nullable = true)\n",
      " |-- CODE_REF_AGENCE_EAU: string (nullable = true)\n",
      " |-- L_REF_AGENCE_EAU: string (nullable = true)\n",
      " |-- L_MOD_CONTACT_PRIVILEGE: string (nullable = true)\n",
      " |-- CODE_HEXAVIA: string (nullable = true)\n",
      " |-- ID_PDS_GEN: string (nullable = true)\n",
      " |-- SIRET: string (nullable = true)\n",
      " |-- NB_LOG: string (nullable = true)\n",
      " |-- NB_MIG: string (nullable = true)\n",
      " |-- NB_PRO: string (nullable = true)\n",
      " |-- NB_TOU: string (nullable = true)\n",
      " |-- NB_UG1: string (nullable = true)\n",
      " |-- NB_UG2: string (nullable = true)\n",
      " |-- NB_UG3: string (nullable = true)\n",
      " |-- NB_UG4: string (nullable = true)\n",
      " |-- NB_UG5: string (nullable = true)\n",
      " |-- FLG_ENT_NAT: string (nullable = true)\n",
      " |-- SOURCE_RELEVE: string (nullable = true)\n",
      " |-- CODE_INT1: string (nullable = true)\n",
      " |-- CODE_INT2: string (nullable = true)\n",
      " |-- SIRET_EMETTEUR: string (nullable = true)\n",
      " |-- FACTURE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=clean_dataset(df,date_columns)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(COMMUNE='MARDIE'),\n",
       " Row(COMMUNE='BOU'),\n",
       " Row(COMMUNE='CHECY'),\n",
       " Row(COMMUNE='CHANTEAU'),\n",
       " Row(COMMUNE='BOIGNY SUR BIONNE'),\n",
       " Row(COMMUNE='COMBLEUX'),\n",
       " Row(COMMUNE='MARIGNY LES USAGES'),\n",
       " Row(COMMUNE='OLIVET'),\n",
       " Row(COMMUNE='None'),\n",
       " Row(COMMUNE='ORMES'),\n",
       " Row(COMMUNE='ST JEAN DE LA RUELLE'),\n",
       " Row(COMMUNE='SAINT JEAN LE BLANC'),\n",
       " Row(COMMUNE='ST JEAN LE BLANC'),\n",
       " Row(COMMUNE='ST PRYVE ST MESMIN'),\n",
       " Row(COMMUNE='ST JEAN DE BRAYE'),\n",
       " Row(COMMUNE='ST CYR EN VAL')]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('COMMUNE').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[COMMUNE: string, MODE_DE_RELEVE: string, COUNT: bigint]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"COMMUNE\", \"MODE_DE_RELEVE\").agg(f.count(\"*\").alias(\"COUNT\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une fonction qui permet de grouper par une colonne et utilise une colonne pivot pour fournir le nombre d'occurences\n",
    "\n",
    "def group_and_pivot(df, group_col, pivot_col):\n",
    "    \"\"\"\n",
    "    Regroupe les données par une colonne et effectue un pivot sur une autre colonne.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): Le DataFrame Spark à traiter.\n",
    "    group_col (str): La colonne utilisée pour le regroupement.\n",
    "    pivot_col (str): La colonne utilisée pour le pivot.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame Pandas contenant les résultats agrégés.\n",
    "    \"\"\"\n",
    "    result_df = df.groupBy(group_col).pivot(pivot_col).count()\n",
    "    return result_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMUNE</th>\n",
       "      <th>null</th>\n",
       "      <th>A pied</th>\n",
       "      <th>Radio-Relevé</th>\n",
       "      <th>Télé-Relevé</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MARDIE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>621</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23893.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST JEAN DE LA RUELLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORMES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1917</td>\n",
       "      <td>73.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MARIGNY LES USAGES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>782</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OLIVET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8058.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SAINT JEAN LE BLANC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ST JEAN LE BLANC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CHECY</td>\n",
       "      <td>3.0</td>\n",
       "      <td>647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3537.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ST PRYVE ST MESMIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHANTEAU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>628</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ST JEAN DE BRAYE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BOIGNY SUR BIONNE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>502.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>COMBLEUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ST CYR EN VAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 COMMUNE  null  A pied  Radio-Relevé  Télé-Relevé\n",
       "0                 MARDIE   NaN     314           2.0       1126.0\n",
       "1                   None   NaN     621          18.0      23893.0\n",
       "2   ST JEAN DE LA RUELLE   NaN      28          46.0          NaN\n",
       "3                  ORMES   NaN    1917          73.0         18.0\n",
       "4                    BOU   NaN      87           NaN        457.0\n",
       "5     MARIGNY LES USAGES   NaN     782           1.0         11.0\n",
       "6                 OLIVET   NaN     186           1.0       8058.0\n",
       "7    SAINT JEAN LE BLANC   NaN       2           NaN          1.0\n",
       "8       ST JEAN LE BLANC   NaN      73           9.0       3278.0\n",
       "9                  CHECY   3.0     647           1.0       3537.0\n",
       "10    ST PRYVE ST MESMIN   NaN      47           2.0       2809.0\n",
       "11              CHANTEAU   NaN     628          25.0          6.0\n",
       "12      ST JEAN DE BRAYE   NaN      47          44.0          1.0\n",
       "13     BOIGNY SUR BIONNE   NaN     588           NaN        502.0\n",
       "14              COMBLEUX   NaN      38           NaN        266.0\n",
       "15         ST CYR EN VAL   NaN      16           1.0        109.0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_and_pivot(df,\"COMMUNE\",\"MODE_DE_RELEVE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une fonction qui retire toutes les colonnes qui n'ont que des valeurs Null\n",
    "def remove_null_columns(df):\n",
    "    \"\"\"\n",
    "    Supprime les colonnes contenant uniquement des valeurs nulles dans un DataFrame PySpark.\n",
    "\n",
    "    :param df: Le DataFrame PySpark à nettoyer.\n",
    "    :return: Le DataFrame sans les colonnes avec uniquement des valeurs nulles.\n",
    "    \"\"\"\n",
    "    non_null_columns = [c for c in df.columns if df.filter(df[c].isNotNull()).count() > 0]\n",
    "    return df.select(*non_null_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une fonction qui retourne entièrement les colonnes nulles \n",
    "def colonnes_nulles(df):\n",
    "    \n",
    "    null_columns = [\n",
    "        col_name\n",
    "        for col_name in df.columns\n",
    "        if df.filter(f.col(col_name).isNotNull()).count() == 0\n",
    "    ]\n",
    "    return null_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes entièrement nulle\n",
    "b=colonnes_nulles(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FORAGE',\n",
       " 'ANC_A_FACTURER',\n",
       " 'BASSINS_VERSANTS',\n",
       " 'NOMBRE_UL',\n",
       " 'CODE_REM4',\n",
       " 'MO_RES',\n",
       " 'NAT_REJ',\n",
       " 'VOLUME_FORAGE_SITE',\n",
       " 'CODE_REF_AGENCE_EAU',\n",
       " 'L_REF_AGENCE_EAU',\n",
       " 'NB_LOG',\n",
       " 'NB_MIG',\n",
       " 'NB_PRO',\n",
       " 'NB_TOU',\n",
       " 'NB_UG1',\n",
       " 'NB_UG2',\n",
       " 'NB_UG3',\n",
       " 'NB_UG4',\n",
       " 'NB_UG5']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=remove_null_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DATE_DEPOSE=datetime.date(2024, 7, 8)),\n",
       " Row(DATE_DEPOSE=datetime.date(2023, 11, 23)),\n",
       " Row(DATE_DEPOSE=datetime.date(2024, 5, 14)),\n",
       " Row(DATE_DEPOSE=None)]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('DATE_DEPOSE').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------------+------------------+---------------------+------------+-----------------------+-------------+-----------+-----------+------------+------------+--------------------+--------------------+--------+-----------------+-----------------+-----------------+---------------------+--------------+-----------+--------------------+----------+----------------+--------------------+--------------------+--------+------------------------+----------+---------------+---------------+-------+--------------------+-------------------+------+----------+-------------------+------------+-------------------+--------------+------------------+--------+-------------+-----------------+---------------+----------------+----------------+-------------------+----------+-------------+-----------------+-----------------+------------------+-----+--------------------+------------------+---------------------+---------+---------+---------+--------------------+---+---------+---------+--------+-----------+---------------+-------------------+----------+---------------------------+-------------------+---------------+------------------+--------+-----------------------+------------+----------+-----+-----------+-------------+---------+---------+--------------+-------+\n",
      "|      PB|CONTRAT_RATTACHEMENT|          COMMUNE|CODE_CYCLE_SERVICE|LIBELLE_CYCLE_SERVICE|CODE_TOURNEE|LIBELLE_TOURNEE_SERVICE|TOURNEE_OPALE|SEQ_TOURNEE|ID_COMPTEUR|NUMERO_BADGE|NUMERO_SERIE|           FABRICANT|              MODELE|DIAMETRE|ANNEE_FABRICATION|SOLUTION_COMPACTE|SOLUTION_DEPORTEE|PASSERELLE_SITE_ISOLE|DATE_RECEPTION|DATE_DEPOSE|MATRICULE_EQUIPEMENT|ACCESSIBLE|CODE_EMPLACEMENT| LIBELLE_EMPLACEMENT|DETAILS_EMPLACEMENTS|  ID_PDS|DATE_MISE_EN_SERVICE_PDS|  ETAT_PDS|ETAT_SOURCE_PDS|LOGEMENT_VACANT|GEN_DIV| RACCORDE_RACORDABLE|DATE_RACCORDABILITE| USAGE|    FLUIDE|MAT_BRANCH_AV_COMPT|MAT_AP_COMPT|CALIBRE_BRANCHEMENT|MODE_DE_RELEVE|BRANCHEMENT_FICTIF| ID_SITE|NUM_VOIE_SITE|     COMMUNE_SITE|CODE_INSEE_SITE|CODE_POSTAL_SITE|ID_COMPTE_CLIENT|ANCIENNE_REF_CLIENT|MENSUALISE|CLASSE_CLIENT|   COMMUNE_CLIENT|CODE_INSEE_CLIENT|CODE_POSTAL_CLIENT|  CMJ|DATE_DERNIERE_RELEVE|       TYPE_RELEVE|INDEX_DERNIERE_RELEVE|CODE_REM1|CODE_REM2|CODE_REM3|DT_FIN_CONTRAT_CADRE|CGC|IMPS_TRRR|TYPE_SITE|CODE_NAF|LIBELLE_NAF|PDS_STRATEGIQUE|CARNET_METROLOGIQUE| ID_ACTEUR|NATURE_CONTRAT_RATTACHEMENT|NATURE_SERV_EAU_ASS|CODE_PROTECTION|ID_DERNIERE_RELEVE|EFACTURE|L_MOD_CONTACT_PRIVILEGE|CODE_HEXAVIA|ID_PDS_GEN|SIRET|FLG_ENT_NAT|SOURCE_RELEVE|CODE_INT1|CODE_INT2|SIRET_EMETTEUR|FACTURE|\n",
      "+--------+--------------------+-----------------+------------------+---------------------+------------+-----------------------+-------------+-----------+-----------+------------+------------+--------------------+--------------------+--------+-----------------+-----------------+-----------------+---------------------+--------------+-----------+--------------------+----------+----------------+--------------------+--------------------+--------+------------------------+----------+---------------+---------------+-------+--------------------+-------------------+------+----------+-------------------+------------+-------------------+--------------+------------------+--------+-------------+-----------------+---------------+----------------+----------------+-------------------+----------+-------------+-----------------+-----------------+------------------+-----+--------------------+------------------+---------------------+---------+---------+---------+--------------------+---+---------+---------+--------+-----------+---------------+-------------------+----------+---------------------------+-------------------+---------------+------------------+--------+-----------------------+------------+----------+-----+-----------+-------------+---------+---------+--------------+-------+\n",
      "|PB ALBOU| AQUAWASH DT - 42257|BOIGNY SUR BIONNE|              0DYL| BOIGNY SUR BIONNE...|        0DYL|   BOIGNY SUR BIONNE...|          1.0|       9700| 8361561125|  1581412316| H24VA169824|Sappel - Diehl Me...|ALTAIR V4 composi...|      15|             2024|              Oui|              Oui|                  Oui|    2024-09-04|       NULL|    11A5241011931007|       OUI|              AJ| Jardin - Accessible|       JARDIN CHIENS| 6447593|              2009-01-01|En service|         Ouvert|            NON| Normal|Raccordable raccordé|         2024-09-05|Normal|Eau Froide|            Inconnu|     Inconnu|               NULL|   Télé-Relevé|              NULL| 5734466|           51|BOIGNY SUR BIONNE|          45034|           45760|      9573027089|   0769603401027901|       NON|  Particulier|BOIGNY SUR BIONNE|            45034|             45760|0,101|          2024-09-04|            Normal|                    0|     NULL|     NULL|     NULL|          2031-09-30|Non|     NULL|01 Maison|    NULL|       NULL|           NULL|               AKDQ|2089525014|                        DSP|                EAU|           NULL|         8,366E+11|     Non|      Pas de préférence|      876561|      NULL| NULL|        Non|Relève à pied|     NULL|     NULL|   9,80683E+13|    OUI|\n",
      "|PB ALBOU| AQUAWASH DT - 42257|BOIGNY SUR BIONNE|              0DYL| BOIGNY SUR BIONNE...|        0DYL|   BOIGNY SUR BIONNE...|          1.0|       6500| 8676907387|  1581250045| A12HA184639|   ABB Kent - Elster|     V100 ou PSMT PC|      15|             2012|              Non|              Non|                  Non|    2020-12-14|       NULL|                NULL|       OUI|              AJ| Jardin - Accessible|              JARDIN|14351824|              2012-01-01|En service|         Ouvert|            NON| Normal|Raccordable raccordé|         2012-01-01|Normal|Eau Froide|            Inconnu|     Inconnu|               NULL|        A pied|              NULL|13000270|           14|BOIGNY SUR BIONNE|          45034|           45760|      9602248704|   0769603401034601|       OUI|  Particulier|BOIGNY SUR BIONNE|            45034|             45760| 0,89|          2024-07-08|Estimation système|                 2848|     NULL|     NULL|     NULL|          2031-09-30|Non|     NULL|01 Maison|    NULL|       NULL|           NULL|        A12HA184639| 838272009|                        DSP|                EAU|           NULL|       8,67911E+11|     Non|      Pas de préférence|      876561|      NULL| NULL|        Non|         NULL|     NULL|     NULL|   9,80683E+13|    OUI|\n",
      "|PB ALBOU| AQUAWASH DT - 42257|BOIGNY SUR BIONNE|              0DYN| BOIGNY SUR BIONNE...|        0DYN|   BOIGNY SUR BIONNE...|          1.0|       8200| 7193175514|  1581257427| H22VA087512|Sappel - Diehl Me...|ALTAIR V4 composi...|      15|             2022|              Oui|              Oui|                  Oui|    2022-12-05|       NULL|                NULL|       OUI|              AC|   Cave - Accessible|              MAISON|15775315|              2022-03-04|En service|         Ouvert|            NON| Normal|Raccordable raccordé|         2022-03-04|Normal|Eau Froide|            Inconnu|     Inconnu|               NULL|        A pied|              NULL|13165782|           17|BOIGNY SUR BIONNE|          45034|           45760|      3995295727|   0769603401059601|       NON|  Particulier|BOIGNY SUR BIONNE|            45034|             45760|0,365|          2024-07-08|Estimation système|                  314|     NULL|     NULL|     NULL|          2031-09-30|Non|     NULL|01 Maison|    NULL|       NULL|           NULL|        H22VA087512|3766466069|                        DSP|                EAU|           NULL|       7,19683E+11|     Non|      Pas de préférence|      876546|      NULL| NULL|        Non|         NULL|     NULL|     NULL|   9,80683E+13|    OUI|\n",
      "|PB ALBOU| AQUAWASH DT - 42257|BOIGNY SUR BIONNE|              0DYM| BOIGNY SUR BIONNE...|        0DYM|   BOIGNY SUR BIONNE...|          1.0|      16000| 6808431272|  1581257036| I21LA342638|         Itron - MID|Aquadis+ MID comp...|      15|             2021|              Oui|              Oui|                  Oui|    2021-12-08|       NULL|                NULL|       OUI|              AJ| Jardin - Accessible|        JARDIN CHIEN|19972677|              2021-08-25|En service|         Ouvert|            NON| Normal|     Non Raccordable|         2021-08-25|Normal|Eau Froide|            Inconnu|     Inconnu|               NULL|        A pied|              NULL|19069844|          733|BOIGNY SUR BIONNE|          45034|           45760|      3172258162|   0769603401081901|       NON|  Particulier|BOIGNY SUR BIONNE|            45034|             45760|0,398|          2024-07-08|Estimation système|                  419|     NULL|     NULL|     NULL|          2031-09-30|Non|     NULL|01 Maison|    NULL|       NULL|           NULL|        I21LA342638|7230005821|                        DSP|                EAU|           NULL|       6,80704E+11|     Non|      Pas de préférence|      876577|      NULL| NULL|        Non|         NULL|     NULL|     NULL|   9,80683E+13|    OUI|\n",
      "|PB ALBOU| AQUAWASH DT - 42257|BOIGNY SUR BIONNE|              0DYN| BOIGNY SUR BIONNE...|        0DYN|   BOIGNY SUR BIONNE...|          1.0|      31200| 5278203184|  1581253384| H23VA431106|Sappel - Diehl Me...|ALTAIR V4 composi...|      15|             2023|              Oui|              Oui|                  Oui|    2024-01-01|       NULL|                NULL|       OUI|              AJ| Jardin - Accessible|              JARDIN|40591673|              2023-09-05|En service|         Ouvert|            NON| Normal|Raccordable raccordé|         2023-09-05|Normal|Eau Froide|            Inconnu|     Inconnu|               NULL|        A pied|              NULL|42818254|           32|BOIGNY SUR BIONNE|          45034|           45760|      3991346832|   0769603401004101|       NON|  Particulier|BOIGNY SUR BIONNE|            45034|             45760|    0|          2024-07-08|Estimation système|                   77|     NULL|     NULL|     NULL|          2031-09-30|Non|     NULL|01 Maison|    NULL|       NULL|           NULL|        H23VA431106|5662208681|                        DSP|                EAU|           NULL|       5,27519E+11|     Non|      Pas de préférence|      876551|      NULL| NULL|        Non|         NULL|     NULL|     NULL|   9,80683E+13|    OUI|\n",
      "|PB ALBOU| AQUAWASH DT - 42257|BOIGNY SUR BIONNE|              0DYM| BOIGNY SUR BIONNE...|        0DYM|   BOIGNY SUR BIONNE...|          1.0|      16100| 1605119344|  1581258248| H20VA054932|Sappel - Diehl Me...|ALTAIR V4 composi...|      15|             2020|              Oui|              Oui|                  Oui|    2020-12-14|       NULL|    11A5242310201007|       OUI|              AT|Trottoir - Access...|           DOM PUBLI|43742351|              2020-10-06|En service|         Ouvert|            NON| Normal|     Non Raccordable|         2024-08-28|Normal|Eau Froide|            Inconnu|     Inconnu|               NULL|   Télé-Relevé|              NULL|49346034|          746|BOIGNY SUR BIONNE|          45034|           45760|      8884403223|   0769603401082001|       NON|  Particulier|BOIGNY SUR BIONNE|            45034|             45760|0,182|          2024-07-08|Estimation système|                  253|     NULL|     NULL|     NULL|          2031-09-30|Non|     NULL|01 Maison|    NULL|       NULL|           NULL|        H20VA054932|7024732098|                        DSP|                EAU|           NULL|       1,60656E+11|     Non|      Pas de préférence|      876577|      NULL| NULL|        Non|         NULL|     NULL|     NULL|   9,80683E+13|    OUI|\n",
      "+--------+--------------------+-----------------+------------------+---------------------+------------+-----------------------+-------------+-----------+-----------+------------+------------+--------------------+--------------------+--------+-----------------+-----------------+-----------------+---------------------+--------------+-----------+--------------------+----------+----------------+--------------------+--------------------+--------+------------------------+----------+---------------+---------------+-------+--------------------+-------------------+------+----------+-------------------+------------+-------------------+--------------+------------------+--------+-------------+-----------------+---------------+----------------+----------------+-------------------+----------+-------------+-----------------+-----------------+------------------+-----+--------------------+------------------+---------------------+---------+---------+---------+--------------------+---+---------+---------+--------+-----------+---------------+-------------------+----------+---------------------------+-------------------+---------------+------------------+--------+-----------------------+------------+----------+-----+-----------+-------------+---------+---------+--------------+-------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer les variables, DATE_RECEPTION, DATE_MISE_EN_SERVICE_PDS, DATE_DERNIERE_RELEVE en timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_to_timestamp(df, columns, date_format=\"dd/MM/yyyy\"):\n",
    "    \"\"\"\n",
    "    Convertir une liste de colonnes en type timestamp dans un DataFrame Spark.\n",
    "    \n",
    "    :param df: DataFrame Spark\n",
    "    :param columns: Liste des colonnes à convertir\n",
    "    :param date_format: Format des dates (par défaut \"dd/MM/yyyy\")\n",
    "    :return: DataFrame avec les colonnes converties\n",
    "    \"\"\"\n",
    "    return df.select(\n",
    "        *[f.to_timestamp(df[col], date_format).alias(col) if col in columns else df[col] for col in df.columns]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer les variables, DATE_RECEPTION, DATE_MISE_EN_SERVICE_PDS, DATE_DERNIERE_RELEVE en timestamp\n",
    "date_columns = [\"DATE_RECEPTION\", \"DATE_MISE_EN_SERVICE_PDS\", \"DATE_DERNIERE_RELEVE\"]\n",
    "df = convert_to_timestamp(df, date_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer les variables diametre et INDEX_DERNIERE_RELEVE en integer et la variable CMJ en double\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer les variables diametre et INDEX_DERNIERE_RELEVE en integer et la variable CMJ en double\n",
    "\n",
    "def convertion_typecol(df, int_columns, double_columns):\n",
    "    \"\"\"\n",
    "    Convertir des colonnes en types spécifiques (int ou double).\n",
    "    \n",
    "    :param df: DataFrame Spark\n",
    "    :param int_columns: Liste des colonnes à convertir en integer\n",
    "    :param double_columns: Liste des colonnes à convertir en double\n",
    "    :return: DataFrame avec les colonnes converties\n",
    "    \"\"\"\n",
    "    # Appliquer les transformations pour chaque type\n",
    "    df = df.select(\n",
    "        *[\n",
    "            f.col(c).cast(\"int\").alias(c) if c in int_columns \n",
    "            else f.col(c).cast(\"double\").alias(c) if c in double_columns \n",
    "            else df[c] \n",
    "            for c in df.columns\n",
    "        ]\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes à transformer\n",
    "int_columns = [\"DIAMETRE\", \"INDEX_DERNIERE_RELEVE\"]\n",
    "double_columns = [\"CMJ\"]\n",
    "\n",
    "# Utilisation de la fonction\n",
    "df = convertion_typecol(df, int_columns, double_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quel est le nombre de compteur *Tele-relevé* et le nombre de compteur *relevé à pied*?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de compteurs télérelevé : 44072\n",
      "Nombre de compteurs relevé à pied : 6021\n"
     ]
    }
   ],
   "source": [
    "# Quel est le nombre de compteur telereve et le nombre de compteur relevé à pied?\n",
    "\n",
    "# Le nombre de compteurs telereleve\n",
    "\n",
    "nb_comptreur_telerev = df.filter(f.col(\"MODE_DE_RELEVE\") == \"Télé-Relevé\").count()\n",
    "\n",
    "# Le nombre de compteur relevé à pied \n",
    "\n",
    "nb_compteur_apied = df.filter(f.col(\"MODE_DE_RELEVE\") == \"A pied\").count()\n",
    "\n",
    "# Affichage des nombres :\n",
    "\n",
    "print(f\"Nombre de compteurs télérelevé : {nb_comptreur_telerev}\")\n",
    "print(f\"Nombre de compteurs relevé à pied : {nb_compteur_apied}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de PDS mis en service en 2023 : 1169\n",
      "Nombre de PDS télérelevés en 2023 : 897\n"
     ]
    }
   ],
   "source": [
    "# Filtrer les PDS mis en service en 2023\n",
    "# Quels est le nombre de PDS mis en service en 2023 ? Quels sont les PDS télé relevé parmi ceux la?\n",
    "\n",
    "pds_2023 = df.filter(f.year(f.col(\"DATE_MISE_EN_SERVICE_PDS\")) == 2023)\n",
    "\n",
    "# Nombre total de PDS mis en service en 2023\n",
    "nb_pds_2023 = pds_2023.count()\n",
    "\n",
    "# Nombre de PDS télérelevés en 2023\n",
    "nb_pds_telereleve_2023 = pds_2023.filter(f.col(\"MODE_DE_RELEVE\") == \"Télé-Relevé\").count()\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Nombre de PDS mis en service en 2023 : {nb_pds_2023}\")\n",
    "print(f\"Nombre de PDS télérelevés en 2023 : {nb_pds_telereleve_2023}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de PDS télérelevés à Boigny sur Bionne : 502\n",
      "Nombre de PDS télérelevés à Boigny sur Bionne avec un diamètre > 40 cm : 2\n"
     ]
    }
   ],
   "source": [
    "# Quel est le nombre de PDS telereleve à la commune de BOIGNY SUR BIONNE? Quels sont sont avec un Diametre > à 40cm?\n",
    "\n",
    "\n",
    "# Filtrer les PDS à la commune de Boigny sur Bionne et télérelevés\n",
    "pds_boigny_telereleve = df.filter((f.col(\"COMMUNE\") == \"BOIGNY SUR BIONNE\") & \n",
    "                                  (f.col(\"MODE_DE_RELEVE\") == \"Télé-Relevé\"))\n",
    "\n",
    "# Nombre total de PDS télérelevés à Boigny sur Bionne\n",
    "nb_pds_boigny_telereleve = pds_boigny_telereleve.count()\n",
    "\n",
    "# Filtrer les PDS télérelevés avec un diamètre > 40 cm\n",
    "pds_boigny_telereleve_diametre_40 = pds_boigny_telereleve.filter(col(\"DIAMETRE\") > 40)\n",
    "\n",
    "# Nombre de PDS télérelevés avec un diamètre > 40 cm\n",
    "nb_pds_boigny_telereleve_diametre_40 = pds_boigny_telereleve_diametre_40.count()\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Nombre de PDS télérelevés à Boigny sur Bionne : {nb_pds_boigny_telereleve}\")\n",
    "print(f\"Nombre de PDS télérelevés à Boigny sur Bionne avec un diamètre > 40 cm : {nb_pds_boigny_telereleve_diametre_40}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de contrats distincts : 1\n",
      "+---------------------------+---------------+\n",
      "|NATURE_CONTRAT_RATTACHEMENT|nombre_communes|\n",
      "+---------------------------+---------------+\n",
      "|                        DSP|             16|\n",
      "+---------------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compter le nombre de contrats distincts\n",
    "nb_contrats = df.select(\"NATURE_CONTRAT_RATTACHEMENT\").distinct().count()\n",
    "\n",
    "# Nombre de communes distinctes par contrat\n",
    "communes_par_contrat = df.groupBy(\"NATURE_CONTRAT_RATTACHEMENT\").agg(\n",
    "    f.countDistinct(\"COMMUNE\").alias(\"nombre_communes\")\n",
    ")\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Nombre de contrats distincts : {nb_contrats}\")\n",
    "communes_par_contrat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+\n",
      "|COMMUNE|nombre_compteurs|\n",
      "+-------+----------------+\n",
      "|   None|             125|\n",
      "+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtrer les compteurs avec un diamètre >= 100 cm\n",
    "df_filtre = df.filter(df[\"DIAMETRE\"] >= 100)\n",
    "\n",
    "# Compter le nombre de compteurs par commune\n",
    "commune_diametre_100 = df_filtre.groupBy(\"COMMUNE\").agg(\n",
    "    f.count(\"*\").alias(\"nombre_compteurs\")\n",
    ")\n",
    "\n",
    "# Trier par le nombre de compteurs et afficher la commune avec le plus grand nombre\n",
    "commune_max_diametre_100 = commune_diametre_100.orderBy(f.col(\"nombre_compteurs\").desc()).limit(1)\n",
    "\n",
    "# Afficher le résultat\n",
    "commune_max_diametre_100.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+\n",
      "|           COMMUNE|nombre_compteurs|\n",
      "+------------------+----------------+\n",
      "|            MARDIE|               2|\n",
      "|             CHECY|               9|\n",
      "| BOIGNY SUR BIONNE|               3|\n",
      "|          COMBLEUX|               2|\n",
      "|MARIGNY LES USAGES|               2|\n",
      "|            OLIVET|              21|\n",
      "|              None|             125|\n",
      "|             ORMES|              21|\n",
      "|  ST JEAN LE BLANC|               7|\n",
      "|ST PRYVE ST MESMIN|               6|\n",
      "|     ST CYR EN VAL|              12|\n",
      "+------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "commune_diametre_100.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the transformations won't display an output and won't be run until an action is called. In the next lecture: Advanced Spark and Python we will begin to see many more examples of this transformation and action relationship!\n",
    "\n",
    "# Great Job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import hashlib\n",
    "from pyspark.sql import functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql import dataframe as pydf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _md5_hash(x, secret_key):\n",
    "    \"\"\"Return the MD5 hash of the value.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : str\n",
    "        The value to anonymize.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The MD5 hash of the value\n",
    "\n",
    "    \"\"\"\n",
    "    return hashlib.md5(x.encode(\"utf-8\") + secret_key.encode(\"utf-8\")).hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f55b7a8749cf57e7853c5a97b223d2d4'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_md5_hash(\"0784808907\",\"svs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "vscode_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
